\documentclass[12pt,letterpaper]{report}
\begin{document}
\section{Introduction}

Do you still know all the words to your favourite song from high school? 
Have you ever heard part of a song and immediately remembered where you were the last time you heard it? 
This is just some anecdotal evidence for the robust nature of musical memory. 
%The robust nature of musical memory is especially apparent in patients with Alzheimer's disease, a disease that results in memory deterioration. Even when other memories are lost, long-term familiarity for melody and music lyrics can be present in severe Alzheimer's disease (Cuddy et al., 2012). 
But, what makes memory for music so special? 
The initial evidence for a distinct memory for music comes from a number of case studies. In 1996, Peretz described patient CN who suffered bilateral temporal lobe damage leading to a severe, music specific agnosia. CN could recognize lyrics from songs, but did not recognize previously familiar melodies. Her normal performance on tests of music perception (melody or tone discrimination) indicated that her agnosia was in fact music-specific and was not a deficit in the processing of melodic information. In contrast, Patient PM (Finke, Esfahani, \& Ploner, 2012), who had been a professional cellist until he contracted encephalitis, had severe semantic and episodic memory deficits but performed like a healthy musician on a music recognition test. PM could not recognize family or friends but he could differentiate between famous and non-famous musical pieces. These case studies indicate that memory for music can be dissociated from other types of memory. 
In fact, Peretz \& Coltheart (2003) proposed that humans have a 'musical lexicon' that contains representations of all the musical phrases one has ever heard, and that this musical lexicon is separate from the verbal lexicon, where representations of phonological sounds are stored. 

Neuroimaging techniques have allowed researchers to uncover the neural basis for the separate musical lexicon described by Peretz and Coltheart. Studies using PET have shown that the musical lexicon, and musical semantic memory in general, is sustained by a temporo-prefrontal cortical network (Groussard et al, 2009). This network showed greater activity during a task where participants rated their level of familiarity with a series of melodies than in a task where participants determined whether two unknown melodies were the same or different. 
%Groussard et al. (2009) hypothesized that the right-sided regions within this network are mainly responsible for holding the melodic traces of familiar tunes, whereas the left-sided regions are responsible for the semantic and associative memories involved in recognizing a musical piece as familiar. 
%The left-sided activation occurred in areas common to those classically shown to be involved in verbal semantic memory (Groussard et al., 2009). 
A clear dissociation between the neural patterns elicited by musical and verbal stimuli was seen in a similar study using fMRI (Groussard et al 2010). 
These neuroimaging results supported the theory of Baird and Samson (2009) who suggested that musical memory in patients with Alzheimer's disease is spared because of the intact functioning of the necessary and specific brain regions that are relatively unaffected by the disease. They suggest that explicit musical memory, that relies on the temporal lobes, is affected by Alzheimer's disease, but other types of musical memory such as procedural musical memory rely on frontal areas and therefore are relatively preserved in Alzheimer's. In 2015, Jacobsen, Fritz, Stelzer, and Turner showed that the caudal anterior cingulate and the ventral pre-supplementary motor areas are involved in the processing of both unknown and known music and that these areas, responsible for encoding musical memory, were relatively spared in a sample of patients with Alzheimer's disease. Together, these results indicate that not only is memory for music separate from other types of memory, but this dissociation can be seen with neuroimaging techniques. 

The current study uses fMRI to define the neural substrates of musical memory. 
Naive subjects train on a set of unfamiliar musical stimuli to induce musical familiarity while the amount of exposure to each stimulus is controlled.
Through comparisons of brain activations of the original unfamiliar stimuli to the newly familiar stimuli we gain a clearer understanding of how brain activity differs when listening to unfamiliar and familiar stimuli and allows us to understand why memory for music is different from other types of memory. 
The stimuli used in this study were carefully manipulated to allow us to dissociate the role that the words (lyrics) play in musical memory. 
Participants listen to stimuli where words are spoken, words are sung without music (a capella), words are sung with music, and where music is heard without words. 
Using these stimuli, we can determine how the presence of lyrics affects musical memory behaviourally and how lyrics relate to changes in BOLD activation levels across familiar and unfamiliar stimuli. 

\section{Methods}
\subsection{Participants}
Participants were recruited for this study on campus at The University of Western Ontario. 
\subsection{Stimuli}
The 16 stimuli were divided into two groups of eight songs (group A and B) with two whole, instrumental, sung, and spoken stimuli in each group.
The stimuli in group A and group B were further divided (for the researchers purposes only - participants were blind to this division) for scanning purposes.
Half of the stimuli (one of each stimulus type) were used in the scanner to measure BOLD responses (short, 10 sec clips), the other half of the stimuli were used to measure inter subject synchrony (5 min version of the song). Only the BOLD results will be discussed here. 
\subsection{Scanning Procedure}
Participants were scanned on a  Siemens Magnetom 7T scanner at the Center for Functional and Metabolic Mapping at the Robarts Research Institute. 
Interleaved slices were collected with the following parameters: 54 slices, voxel size $2.5mm^3$, matrix size of ,  TE = 20ms, TR = 1250m, flip angle = $35^{\circ}$. 
In the scanner the participants listened to 16 unfamiliar stimuli. 
The 80 musical clips selected for measure BOLD responses were played to participants in a random order during the scan. 


After the scan, participants were assigned to either group A or group B stimuli. They were instructed to listen to the eight songs once per day (minimum five times per week) using our online music player. 
The music player recorded the number of times each song was listened to and presented participants with a simple question after a randome number of songd to ensure that the participants were still listening and paying attention to the stimuli. 
The participants trained on the songs over the course of 2-3 weeks and came into the lab for behavioural testing twice a week. 
In each lab session participants listened to the songs and completed a number of behavioural tasks. These behavioural tasks are discussed in the next section. 
After a 2-3 week period participants returned to the scanner for their second scan. The second scan was identical to the first.
\subsection{Behavioural tasks}
During the training period, participants came into the lab twice a week.
Each session lasted less than an hour.
Participants listened to their songs in the lab and completed 2-3 of the following behavioural tasks. 
\subsubsection{Lyric Modification}
The lyric modification task presented participants with pairs of lyrics.
Each pair consisted of a lyric taken directly from their stimuli training group and a modified version of the same lyric. 
Participants indicated which lyric was the correct lyric.
The lyric pairs were tested for their validity before being included in this study. 
Before the first scan session, participants were presented with the entire set of 25 lyric pairs.
In each behavioural session, participants responded to a subset of 10 lyric pairs. 
Once participants responded with accuracy over 90\% they were schedule for their second scanning session.
Before the second scan session participants completed the full set of 25 lyric pairs again. 
\subsubsection{Preference Ratings}
After listening to each song, participants rated on a scale of 1-7 how much they liked the song.
The preference ratings were completed after each scan and behavioural session. 
These ratings allowed us to track how preference changed with as familiarity increased.
\subsubsection{GMSI}
Participants completed the Goldsmith's Musical Sophistication Index (GMSI).
The GMSI includes a questionnaire regarding musical abilities training, a test of melodic memory, and a test of beat perception.
Each section of the GMSI was completed during separate behavioural sessions. 
\subsubsection{Other tasks}
Participants completed a musical associations form where they were asked to describe any associations they had with each song (e.g. memories, songs they are reminded of, etc.) and a lyric orientation questionnaire (SKIDMORE). 
After the second scan session participants also completed a melody recognition task. 
Participants were played two clips consecutively. 
One clip was from a song they trained on and the second clip was from one of the untrained songs. 
Participants indicated which of the clips was from a trained song.
\section{Acknowledgements}
Brain Canada Funding
\end{document}